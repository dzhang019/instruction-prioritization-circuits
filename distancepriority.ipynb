{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6006cafb",
   "metadata": {},
   "source": [
    "### testing the importance of distance on instruction priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fc00df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.6.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.4.1+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub\n",
    "%pip install python-dotenv\n",
    "%pip install huggingface\n",
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install matplotlib\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd880f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"DATASETS_DISABLE_PROGRESS_BAR\"] = \"1\"\n",
    "\n",
    "load_dotenv()\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59aee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "The token `a3` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `a3`\n"
     ]
    }
   ],
   "source": [
    "!hf auth login --token {huggingface_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2edb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aeb13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load wiki\n",
    "ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a35e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(type(ds))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b6db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' = = Gameplay = = \\n'}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3deeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_row(example):\n",
    "    text = example['text']\n",
    "    if not text:\n",
    "        return False\n",
    "    if text == \"\\n\":\n",
    "        return False\n",
    "    # if text.startswith(\"=\"):\n",
    "    #     return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35885c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_wiki = ds.filter(keep_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97133e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2-9b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c25fdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenize dataset\n",
    "full_text = \"\\n\".join([line for line in filtered_wiki[\"train\"][\"text\"]])\n",
    "all_tokens = tokenizer.encode(full_text, add_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ba58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_wiki_slice(n_tokens):\n",
    "    start_idx = random.randint(0, len(all_tokens) - n_tokens - 1)\n",
    "    return all_tokens[start_idx : start_idx + n_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2e4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Your goal is to respond to the user's request while making sure his instructions are fully satistfied. An instruction will appear in the form 'Instruction: <INSTRUCTION>.'\\n\"\n",
    "\n",
    "end_question = \"\\nNow, provide your response based on the previous instructions. \\n\"\n",
    "\n",
    "instruction_set = {\n",
    "    \"language\": [\"Respond in French.\", \"Respond in German.\"],\n",
    "    \"first_word\": [\"Begin your response with the word 'CHERRY'.\", \"Begin your response with the word 'APPLE'.\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "642cc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_token_span(target_ids, full_ids):\n",
    "    n = len(target_ids)\n",
    "    for i in range(len(full_ids) - n + 1):\n",
    "        if full_ids[i : i + n] == target_ids:\n",
    "            return i, i + n\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cce4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_single_instr_prompt(instr_text, pos_pct, total_length=2048):\n",
    "    formatted_instr = f\"\\n\\nInstruction: {instr_text}\\n\\n\"\n",
    "    \n",
    "    dummy_messages = [{\"role\": \"user\", \"content\": \"DUMMY\"}]\n",
    "    dummy_ids = tokenizer.apply_chat_template(dummy_messages, tokenize=True, add_generation_prompt=True)\n",
    "    template_overhead = len(dummy_ids) - len(tokenizer.encode(\"DUMMY\", add_special_tokens=False))\n",
    "    \n",
    "    instr_tokens = tokenizer.encode(formatted_instr, add_special_tokens=False)\n",
    "    sys_tokens = tokenizer.encode(system_prompt, add_special_tokens=False)\n",
    "    end_tokens = tokenizer.encode(end_question, add_special_tokens=False)\n",
    "    \n",
    "    fixed_parts_len = len(sys_tokens) + len(instr_tokens) + len(end_tokens) + template_overhead\n",
    "    filler_budget = total_length - fixed_parts_len\n",
    "    \n",
    "    if filler_budget < 0:\n",
    "        raise ValueError(f\"Instructions too long! Overhead is {fixed_parts_len}\")\n",
    "\n",
    "    filler_tokens = get_r_wiki_slice(filler_budget)\n",
    "    split_idx = int(pos_pct * filler_budget)\n",
    "    \n",
    "    user_content = (\n",
    "        system_prompt + \n",
    "        tokenizer.decode(filler_tokens[:split_idx]) + \n",
    "        formatted_instr + \n",
    "        tokenizer.decode(filler_tokens[split_idx:]) + \n",
    "        end_question\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": user_content}]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=True, \n",
    "        add_generation_prompt=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    if input_ids.shape[1] != total_length:\n",
    "        diff = input_ids.shape[1] - total_length\n",
    "        if diff > 0:\n",
    "\n",
    "            input_ids = torch.cat([input_ids[:, :10], input_ids[:, 10+diff:]], dim=1)\n",
    "        else:\n",
    "            padding = torch.full((1, abs(diff)), tokenizer.pad_token_id).to(input_ids.device)\n",
    "            input_ids = torch.cat([input_ids[:, :10], padding, input_ids[:, 10:]], dim=1)\n",
    "\n",
    "    return input_ids, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40dbe7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 1024\n",
      "End of prompt tokens: [611, 573, 4509, 12027, 235265, 107, 108, 106, 2516, 108]\n",
      "End of prompt decoded: ', provide your response based on the previous instructions.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "test_ids, _ = construct_single_instr_prompt(\"Begin with CHERRY\", 0.5, 1024)\n",
    "print(f\"Total length: {test_ids.shape[1]}\")\n",
    "print(f\"End of prompt tokens: {test_ids[0, -10:].tolist()}\")\n",
    "print(f\"End of prompt decoded: '{tokenizer.decode(test_ids[0, -15:])}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3b2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_ids = [\n",
    "    tokenizer.encode(\" CHERRY\", add_special_tokens=False)[0],\n",
    "    tokenizer.encode(\"CHERRY\\n\", add_special_tokens=False)[0],\n",
    "    tokenizer.encode(\"CHERRY \", add_special_tokens=False)[0],\n",
    "    tokenizer.encode(\"CHERRY\", add_special_tokens=False)[0],\n",
    "    tokenizer.encode(\"\\nCHERRY\", add_special_tokens=False)[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a897ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_position_sweep(model, instr_text, total_length, samples_per_pos=100, batch_size=2):\n",
    "    device = next(model.parameters()).device\n",
    "    pcts = np.linspace(0.0, 1.0, 21)\n",
    "    target_token_id = tokenizer.encode(\" CHERRY\", add_special_tokens=False)[0]\n",
    "    \n",
    "    results = {round(pct, 2): {\"logits\": [], \"is_correct\": []} for pct in pcts}\n",
    "    # This will now store a LIST of completions for each position\n",
    "    decoded_completions = {round(pct, 2): [] for pct in pcts}\n",
    "    \n",
    "    model.eval()\n",
    "    for pct in pcts:\n",
    "        pct_key = round(pct, 2)\n",
    "        print(f\"Processing Position: {pct_key:.2f}\")\n",
    "        \n",
    "        num_batches = (samples_per_pos + batch_size - 1) // batch_size\n",
    "        \n",
    "        # Determine which specific global indices we want to decode (5%)\n",
    "        num_to_decode = math.ceil(0.05 * samples_per_pos)\n",
    "        decode_indices = set(random.sample(range(samples_per_pos), num_to_decode))\n",
    "        \n",
    "        global_idx = 0 \n",
    "\n",
    "        for b in tqdm(range(num_batches)):\n",
    "            batch_list = []\n",
    "            for _ in range(batch_size):\n",
    "                if len(batch_list) + b*batch_size < samples_per_pos: # Handle final uneven batch\n",
    "                    ids, _ = construct_single_instr_prompt(instr_text, pct, total_length)\n",
    "                    batch_list.append(ids)\n",
    "            \n",
    "            batch_tensor = torch.cat(batch_list, dim=0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch_tensor)\n",
    "                last_token_logits = outputs.logits[:, -1, :] \n",
    "            \n",
    "            # Logit/Accuracy Data\n",
    "            cherry_logits = last_token_logits[:, target_token_id].cpu().tolist()\n",
    "            results[pct_key][\"logits\"].extend(cherry_logits)\n",
    "            \n",
    "            predictions = torch.argmax(last_token_logits, dim=-1)\n",
    "            correct_mask = [p.item() in cherry_ids for p in predictions]\n",
    "            results[pct_key][\"is_correct\"].extend(correct_mask)\n",
    "            \n",
    "\n",
    "            # decoded_batch = tokenizer.batch_decode(gen_ids[:, total_length:], skip_special_tokens=True)\n",
    "            # is_correct = [\"CHERRY\" in resp.upper() for resp in decoded_batch]\n",
    "            # results[pct_key][\"is_correct\"].extend(is_correct)\n",
    "\n",
    "            # --- THE SANITY CHECK DECODE ---\n",
    "            # We check each item in the current batch to see if its global index is in our 5% set\n",
    "            for i in range(len(batch_list)):\n",
    "                if global_idx in decode_indices:\n",
    "                    with torch.no_grad():\n",
    "                        # Generate for just this one sequence\n",
    "                        gen_ids = model.generate(\n",
    "                            batch_tensor[i:i+1], \n",
    "                            max_new_tokens=15, # Increased to see the full context of the failure\n",
    "                            do_sample=False,\n",
    "                            pad_token_id=tokenizer.eos_token_id\n",
    "                        )\n",
    "                        # Extract and store completion only\n",
    "                        completion = tokenizer.decode(gen_ids[0, total_length:], skip_special_tokens=True)\n",
    "                        decoded_completions[pct_key].append(completion)\n",
    "                \n",
    "                global_idx += 1\n",
    "            \n",
    "            del outputs\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return results, decoded_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05d38d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b2fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Position: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decoded_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# --- Execution ---\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Start with a shorter haystack to confirm the trend fast\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m sweep_data, examples \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_position_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst_word\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6144\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_per_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m plot_dual_results(sweep_data)\n",
      "Cell \u001b[0;32mIn[21], line 46\u001b[0m, in \u001b[0;36mbatched_position_sweep\u001b[0;34m(model, instr_text, total_length, samples_per_pos, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m results[pct_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_correct\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(correct_mask)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# decoded_batch = tokenizer.batch_decode(gen_ids[:, total_length:], skip_special_tokens=True)\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m is_correct \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHERRY\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdecoded_batch\u001b[49m]\n\u001b[1;32m     47\u001b[0m results[pct_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_correct\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(is_correct)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# --- THE SANITY CHECK DECODE ---\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# We check each item in the current batch to see if its global index is in our 5% set\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_batch' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_dual_results(results):\n",
    "    x = sorted(results.keys())\n",
    "    \n",
    "    # Prepare Data\n",
    "    logit_means = [np.mean(results[pct][\"logits\"]) for pct in x]\n",
    "    logit_stds = [np.std(results[pct][\"logits\"]) for pct in x]\n",
    "    accuracy = [np.mean(results[pct][\"is_correct\"]) for pct in x]\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot Logits\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Position (0.0=Start, 1.0=End)')\n",
    "    ax1.set_ylabel('Logit Magnitude (CHERRY)', color=color)\n",
    "    ax1.errorbar(x, logit_means, yerr=logit_stds, fmt='-o', color=color, label='Logit')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Plot Accuracy on second axis\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Accuracy (Was CHERRY Top-1)', color=color)\n",
    "    ax2.plot(x, accuracy, '-s', color=color, label='Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylim(-0.1, 1.1) # Accuracy is 0 to 1\n",
    "\n",
    "    plt.title(f\"Instruction Salience:\")\n",
    "    fig.tight_layout()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# --- Execution ---\n",
    "# Start with a shorter haystack to confirm the trend fast\n",
    "sweep_data, examples = batched_position_sweep(model, instruction_set[\"first_word\"][0], total_length=6144, samples_per_pos=20)\n",
    "plot_dual_results(sweep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: ['CHERRY  This is a biography of Wilhelm Busch, a German author and', 'CHERRY  This is a text about actor and comedian Adrian Dunbar and his', 'CHERRY  The provided text discusses various aspects of stars, including their luminosity'], 0.05: ['CHERRY  The Qedarites were a nomadic Arab tribal confederation that', 'CHERRY  \\n\\nGregory Helms, better known by his wrestling personas \"The', 'CHERRY The ships had a tertiary armament for protection against torpedo boats in the'], 0.1: ['CHERRY  The 3rd Light Horse Brigade halted at Hill 7', 'CHERRY  The text you provided describes the history of the Réunion solitaire,', 'CHERRY  The text you provided describes the rules of the key in basketball'], 0.15: ['CHERRY  The NTSB determined that the probable cause of the accident was', 'CHERRY  Anderson has been widely praised for his filmmaking talent, with many', 'CHERRY  This is a fascinating biography of R.C.  Wheeler'], 0.2: ['CHERRY  The Battle of Hubbardton was a significant engagement in the Saratoga', 'CHERRY  The death of Pope Clement XIII in 1769', 'CHERRY  The Middle Colonies were a region of great economic and social diversity'], 0.25: ['CHERRY  This text provides a detailed account of the Mozambican War', 'CHERRY  The novel \"The General in His Labyrinth\" by Gabriel García', 'CHERRY  Ireland has a rich and diverse cultural heritage, with contributions to'], 0.3: ['CHERRY  This is a fascinating account of the life and travels of M', 'CHERRY This is a fascinating account of the origins of the \"Bodyline', 'CHERRY  The text you provided is a collection of information about various topics'], 0.35: ['CHERRY  The 2 / 4th Machine Gun Battalion was a', 'CHERRY  This is a collection of text snippets about various topics:\\n\\n', 'CHERRY  The text you provided is a detailed account of the Zeeb'], 0.4: ['CHERRY  The provided text is a detailed description of the Hindu goddess Ban', \"CHERRY  The provided text offers a comprehensive overview of Croatia's political\", \"CHERRY  Wilhelm Busch's literary and artistic career spanned several decades,\"], 0.45: [\"CHERRY  \\n\\nNorman Finkelstein's academic career has been marked by\", 'CHERRY  The Glorious First of June was a significant naval battle during the', 'CHERRY\\n\\nThe provided text details the history of Artificial Intelligence (AI),'], 0.5: ['CHERRY  The fieldfare is a migratory thrush with a distinctive song that', 'CHERRY  \\n\\nGhost in the Shell is a groundbreaking anime film that explores', 'CHERRY\\n\\nThis text provides a detailed description of various caves and sculptures found'], 0.55: ['CHERRY  The text you provided discusses the history and evolution of sentence spacing', 'CHERRY\\n\\nThe Jin leadership had not expected or desired the fall of the', \"CHERRY  This is a biography of Roger Federer's tennis career,\"], 0.6: ['CHERRY The kakapo is a fascinating and unique bird with a number of', 'CHERRY  The HMS Black Prince was a Duke of Edinburgh class armored cruiser', 'CHERRY  The provided text details the history of Lock Haven, Pennsylvania,'], 0.65: [\"CHERRY  England's rugby history is rich and storied, marked\", 'CHERRY  This text provides information about six tropical cyclones that occurred during a', 'CHERRY  This text provides a comprehensive overview of Partington, a town'], 0.7: ['CHERRY  Sarnia is a vibrant city located in Ontario, Canada,', 'CHERRY  The Battle of Grand Port was a significant naval engagement during the', 'CHERRY  The Missouri River, a mighty waterway flowing through the heart of'], 0.75: ['CHERRY\\n\\nThe provided text discusses various aspects of proteins, including their structure', \"CHERRY  Eaton's early career in the Royal Flying Corps and\", 'CHERRY  The Frank Slide was a devastating rockslide that occurred in '], 0.8: ['CHERRY  The provided text details the life and legacy of Zhou Tong,', 'CHERRY  Galveston, Texas, is a coastal city with a rich', \"CHERRY  The text you provided gives a detailed overview of Carre's\"], 0.85: ['CHERRY  This is a comprehensive biography of Dr. Katherine Pulaski from Star', 'CHERRY  The provided text is a detailed account of the 19', 'CHERRY-PICKING the most relevant information from the text, we can'], 0.9: ['CHERRY  This text provides a detailed account of the Simpsons episode \"Bart', \"CHERRY  The provided text discusses the Somerset County Cricket Club's performance\", 'CHERRY  This is a biography of Edward Grant Barrow, a prominent figure'], 0.95: ['CHERRY\\n\\nJifna has a long and rich history, with evidence', 'CHERRY\\n\\nThe Merville Battery was a formidable German coastal defense position that', 'CHERRY\\n\\nThe text you provided describes the events of the uprising in eastern'], 1.0: ['CHERRY\\n\\nThis text provides a detailed history of Bradford City Football Club,', 'CHERRY-picked information about the song \"Don\\'t You Wanna Stay', 'CHERRY  Hydnellum peckii, also known as the \"ble']}\n"
     ]
    }
   ],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94885878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d456e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1083c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801cb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "for name in (\"trainer\",\"model\",\"optim\",\"scheduler\"):\n",
    "    if name in globals(): del globals()[name]\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
